?points()
?postscript()
?points()
?postscript()
?windows()
?bwplot()
?histogram()
?coplot()
?xyplot()
?lines()
?pch
?xyplot()
library(lattice)
?xyplot()
?axis()
?lsegments()
?mtext()
?lines()
?expression()
?substitute()
?expression()
x <- scan()
hist(x)
hist(x,breaks=50)
hist(x,breaks=100)
hist(x,breaks=1000)
hist(x,breaks=10000)
hist(x,breaks=1000)
hist(x,breaks=1000, ylim=100)
hist(x,breaks=1000, ylim=c(0,100))
hist(x,breaks=1000, ylim=c(0,60))
hist(x,breaks=1000, ylim=c(0,50))
hist(x,breaks=1000, ylim=c(0,50), main="distribution of articles in 500 journals")
hist(x,breaks=1000, ylim=c(0,50))
hist(x,breaks=1000, ylim=c(0,50), xlim(0,700))
hist(x,breaks=1000, ylim=c(0,50), xlim=c(0,700))
hist(x,breaks=500, ylim=c(0,50), xlim=c(0,700))
hist(x,breaks=500, ylim=c(0,60), xlim=c(0,700))
hist(x,breaks=500, ylim=c(0,70), xlim=c(0,700))
hist(x,breaks=500, ylim=c(0,70), xlim=c(0,700), ylab="journals")
hist(x,breaks=500, ylim=c(0,70), xlim=c(0,700), ylab="Freq. of Journals")
hist(x,breaks=500, ylim=c(0,70), xlim=c(0,700), ylab="No. of Journals")
hist(x,breaks=500, ylim=c(0,70), xlim=c(0,700), ylab="No. of Journals", xlab="No. of Articles")
hist(x,breaks=500, ylim=c(0,70), xlim=c(0,650), ylab="No. of Journals", xlab="No. of Articles")
hist(x,breaks=500, ylim=c(0,70), xlim=c(0,700), ylab="No. of Journals", xlab="No. of Articles")
hist(x,breaks=500, ylim=c(0,70), xlim=c(0,700), ylab="No. of Journals", xlab="No. of Articles", main="Histogram")
source('~/.active-rstudio-document')
library(devtools)
#knitr::knit('report.Rnw')
#system('pdflatex report.tex')
library(rImpactStory)
df <- github_report("p6y531")
View(df)
df <- collection_metrics("p6y531")
fix(df)
save_collection("p6y531",'/home/ross/workspace/ImpactReport')
save_collection("p6y531",'/home/ross/workspace/ImpactReport/palonline.csv')
fix(df)
save_collection("y5y7xb",'/home/ross/workspace/ImpactReport/blog.csv')
df <- collection_metrics("y5y7xb")
write.csv(df,file="df")
write.table(df,file="df")
fix(df)
fix(df)
save(df,file="df.Rda")
save(df,file="/home/ross/workspace/ImpactReport/df.Rda")
fix(df)
df
fix(df)
save_collection("tqc6tz",'/home/ross/workspace/ImpactReport/blog')
save_collection("y5y7xb",'/home/ross/workspace/ImpactReport/blog')
save_collection("tqc6tz",'/home/ross/workspace/ImpactReport/cv')
library(rplos)
fish <- c(0.422,0.278,0.472,0.121,0.721,0.780,0.052,0.977,0.781,0.046,0.600,0.257,0.344,0.072)
ornithodira <- c(0.057,0.137,0.216,0.329,0.714,0.944,0.203,0.349,0.889,0.295,0.774,0.774,0.033,0.051,0.977,0.593)
t.test(fish,ornithodira)
setwd("/home/ross/workspace/mygithub/phylofigure-captions/caption-per-file")
library(tm)
library(foreign)
#install.packages("SnowballC")
library(SnowballC)
library(wordcloud)
#guide http://onepager.togaware.com/TextMiningO.pdf
cname1 <- file.path(".", "393-yes-zootaxa")
length(dir(cname1))
dir(cname1)
ztpos <- Corpus(DirSource(cname1))
ztpos
cname2 <- file.path(".", "16739-no-zootaxa")
length(dir(cname2))
dir(cname2)
ztneg <- Corpus(DirSource(cname2))
ztneg
cname3 <- file.path(".", "3923-yes-pone")
length(dir(cname3))
dir(cname3)
ponepos <- Corpus(DirSource(cname3))
ponepos
inspect(ponepos[17])
#Corpus names:
# ztpos = Zootaxa phylogeny figure captions
# ztneg = Zootaxa figure captions NOT associated with phylogeny figure image
# ponepos = PLOS ONE phylogeny figure captions
# replace / @ | with a space
#ztpos <- tm_map(ztpos, toSpace, "/|@|nn|")
#ztneg <- tm_map(ztneg, toSpace, "/|@|nn|")
#ponepos <- tm_map(ponepos, toSpace, "/|@|nn|")
#Cleaning data
toSpace <- content_transformer(function(x, pattern) gsub(pattern, " ", x))
ztpos <- tm_map(ztpos, toSpace, "@")
ztneg <- tm_map(ztneg, toSpace, "@")
ponepos <- tm_map(ponepos, toSpace, "@")
ztpos <- tm_map(ztpos, toSpace, "\\.")
ztneg <- tm_map(ztneg, toSpace, "\\.")
ponepos <- tm_map(ponepos, toSpace, "\\.")
ztpos <- tm_map(ztpos, removeNumbers)
ztneg <- tm_map(ztneg, removeNumbers)
ponepos <- tm_map(ponepos, removeNumbers)
ztpos <- tm_map(ztpos, removePunctuation)
ztneg <- tm_map(ztneg, removePunctuation)
ponepos <- tm_map(ponepos, removePunctuation)
ztpos <- tm_map(ztpos, removeWords, stopwords("english"))
ztneg <- tm_map(ztneg, removeWords, stopwords("english"))
ponepos <- tm_map(ponepos, removeWords, stopwords("english"))
ztpos <- tm_map(ztpos, stripWhitespace)
ztneg <- tm_map(ztneg, stripWhitespace)
ponepos <- tm_map(ponepos, stripWhitespace)
inspect(ztpos[16])
#Stemming with Snowball C
ztpos <- tm_map(ztpos, stemDocument)
ztneg <- tm_map(ztneg, stemDocument)
ponepos <- tm_map(ponepos, stemDocument)
inspect(ztpos[16])
dtmztpos <- DocumentTermMatrix(ztpos) #slowstep
dtmztneg <- DocumentTermMatrix(ztneg) #slowstep
dtmponepos <- DocumentTermMatrix(ponepos) #slowstep
#dtm2 <- removeSparseTerms(dtm, sparse=0.95)
str(dtmztpos)
dtmztpos$Terms
freq <- colSums(as.matrix(dtmztpos))
length(freq)
ord <- order(freq)
# Most frequent terms
freq[tail(ord)]
m <- as.matrix(dtmztpos)
write.csv(m, file="dtmztpos.csv")
dtmponepos
dtmp1pos <- removeSparseTerms(dtmponepos, sparse=0.985)
dtmp1pos
m3 <- as.matrix(dtmp1pos)
write.csv(m3, file="dtmp1pos.csv")
dtmztneg
dtmztneg.sparse <- removeSparseTerms(dtmztneg, sparse=0.995)
dtmztneg.sparse
m4 <- as.matrix(dtmztneg.sparse)
write.csv(m4, file="dtmztnegsparse.csv")
wordFreq <- sort(colSums(m), decreasing=TRUE)
#Remove 'FIGURE'
wordFreq <- wordFreq[-1]
set.seed(375) # to make it reproducible
grayLevels <- gray( (wordFreq+10) / (max(wordFreq)+10) )
png("wordcloud_zootaxa_phylo.png", width=12,height=8, units='in', res=300)
wordcloud(words=names(wordFreq), freq=wordFreq, min.freq=5, max.words=500 , random.order=F, colors=grayLevels)
dev.off()
warnings()
cname1 <- file.path(".", "393-yes-zootaxa")
length(dir(cname1))
dir(cname1)
ztpos <- Corpus(DirSource(cname1))
setwd("/home/ross/workspace/mygithub/phylofigure-captions/caption-per-file")
library(tm)
library(foreign)
#install.packages("SnowballC")
library(SnowballC)
library(wordcloud)
#guide http://onepager.togaware.com/TextMiningO.pdf
cname1 <- file.path(".", "393-yes-zootaxa")
length(dir(cname1))
dir(cname1)
ztpos <- Corpus(DirSource(cname1))
ztpos
cname2 <- file.path(".", "16739-no-zootaxa")
length(dir(cname2))
dir(cname2)
ztneg <- Corpus(DirSource(cname2))
ztneg
cname3 <- file.path(".", "3923-yes-pone")
length(dir(cname3))
dir(cname3)
ponepos <- Corpus(DirSource(cname3))
ponepos
inspect(ponepos[17])
inspect(ztpos[16])
toSpace <- content_transformer(function(x, pattern) gsub(pattern, " ", x))
getTransformation()
library(tm)
sessionInfo()
getRversion()
getTransformation()
ztpos <- tm_map(ztpos, toSpace, "@")
toSpace <- content_transformer(function(x, pattern) gsub(pattern, " ", x))
ztpos <- tm_map(ztpos, toSpace, "@")
ztneg <- tm_map(ztneg, toSpace, "@")
ponepos <- tm_map(ponepos, toSpace, "@")
ztpos <- tm_map(ztpos, toSpace, "\\.")
ztneg <- tm_map(ztneg, toSpace, "\\.")
ponepos <- tm_map(ponepos, toSpace, "\\.")
ztpos <- tm_map(ztpos, removeNumbers)
ztneg <- tm_map(ztneg, removeNumbers)
ponepos <- tm_map(ponepos, removeNumbers)
ztpos <- tm_map(ztpos, removePunctuation)
ztneg <- tm_map(ztneg, removePunctuation)
ponepos <- tm_map(ponepos, removePunctuation)
ztpos <- tm_map(ztpos, removeWords, stopwords("english"))
ztneg <- tm_map(ztneg, removeWords, stopwords("english"))
ponepos <- tm_map(ponepos, removeWords, stopwords("english"))
ztpos <- tm_map(ztpos, stripWhitespace)
ztneg <- tm_map(ztneg, stripWhitespace)
ponepos <- tm_map(ponepos, stripWhitespace)
inspect(ztpos[16])
cname1 <- file.path(".", "393-yes-zootaxa")
length(dir(cname1))
dir(cname1)
ztpos <- Corpus(DirSource(cname1))
ztpos
cname2 <- file.path(".", "16739-no-zootaxa")
length(dir(cname2))
dir(cname2)
ztneg <- Corpus(DirSource(cname2))
ztneg
cname3 <- file.path(".", "3923-yes-pone")
length(dir(cname3))
dir(cname3)
ponepos <- Corpus(DirSource(cname3))
ponepos
inspect(ponepos[17])
inspect(ztpos[16])
tm?
)
?tm
??tm
getTransformation()
library(tm)
getTransformation()
updateR()
install.package(installr)
install.packages("installr")
